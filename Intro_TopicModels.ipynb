{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_TopicModels.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/librairy/notebooks/blob/master/Intro_TopicModels.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "AVx3oh5JCi_F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This Google Colab Notebook serves as an introduction to Probabilistic Topic Models. \n",
        "\n",
        "Textual data can be loaded from a Google Sheet and topics derived from  LDA can be generated. \n",
        "\n",
        "First, it is necessary to indicate the training google sheet and the number of words to show per topic.\n"
      ]
    },
    {
      "metadata": {
        "id": "UcubynMaDbzt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Google Colab Authentication\n",
        "!pip install --upgrade -q gspread\n",
        "#!pip install -q gensim\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
        "    for topic_idx, topic in enumerate(H):\n",
        "        print(\"-\"*30)\n",
        "        print(\" Topic \",(topic_idx),\" :\")\n",
        "        print(\"[\",\" | \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]),\"]\")\n",
        "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
        "        for doc_index in top_doc_indices:\n",
        "            print(\"(\",doc_index+2,\")\",documents[doc_index][:100],\" ...\")\n",
        "            print(\"\\t\",W[doc_index])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXu9rcR2Dmz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "b137641a-5628-4eb8-ca93-56a40b8c5d47"
      },
      "cell_type": "code",
      "source": [
        "#@title Load and preview data from a Google Sheet\n",
        "\n",
        "corpus = 'texts' #@param {type:\"string\"}\n",
        "preview = 10 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open(corpus).sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# convert the 2nd column values to a list\n",
        "documents = []\n",
        "for row in rows[1:]:\n",
        "  documents.append(row[1])\n",
        "  \n",
        "#print(documents)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "dataset_df = pd.DataFrame.from_records(rows)\n",
        "dataset_df.head(n=preview)\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dean J. Falcione (posting from jrmst+8@pitt.ed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>In article &lt;1993Mar29.190650.28940@ramsey.cs.l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>I can only comment on the Kings, but the most ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>In article &lt;C4zCII.Ftn@watserv1.uwaterloo.ca&gt; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Maine beat LSSU 5-4.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Well, I gotta tell ya, last night's Leafs game...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>&gt;The shirts are believe or not from a Bob Prob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Lake State/Maine in finals...WHO WON?   Please...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Also sprach slegge@kean.ucs.mun.ca ... &gt;TSN Sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>In article &lt;C4zHJ1.7xB@idacom.hp.com&gt; andrew@i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0                                                  1\n",
              "0   1  Dean J. Falcione (posting from jrmst+8@pitt.ed...\n",
              "1   2  In article <1993Mar29.190650.28940@ramsey.cs.l...\n",
              "2   3  I can only comment on the Kings, but the most ...\n",
              "3   4  In article <C4zCII.Ftn@watserv1.uwaterloo.ca> ...\n",
              "4   5                               Maine beat LSSU 5-4.\n",
              "5   6  Well, I gotta tell ya, last night's Leafs game...\n",
              "6   7  >The shirts are believe or not from a Bob Prob...\n",
              "7   8  Lake State/Maine in finals...WHO WON?   Please...\n",
              "8   9  Also sprach slegge@kean.ucs.mun.ca ... >TSN Sp...\n",
              "9  10  In article <C4zHJ1.7xB@idacom.hp.com> andrew@i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "ChKtbgQldfTf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize input data:\n"
      ]
    },
    {
      "metadata": {
        "id": "BwiEHyUEdhOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9ccd54e-acda-4ebe-dd06-8b44bcf8f020"
      },
      "cell_type": "code",
      "source": [
        "#@title Tokenization\n",
        "\n",
        "tf_vectorizer = CountVectorizer(\n",
        "    stop_words=None,\n",
        "    min_df=1,\n",
        "    max_df=0.95,\n",
        "    lowercase=False,\n",
        "    ngram_range=(1,1),\n",
        "    analyzer = 'word'\n",
        ")\n",
        "tf = tf_vectorizer.fit_transform(documents)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "vocab = tf_vectorizer.vocabulary_\n",
        "\n",
        "print(\"Vocabulary Size: \", len(tf_feature_names))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  5189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lmTsfABkDzF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now it's time to build a topic model by setting values for:\n",
        "- number of topics\n",
        "- alpha\n",
        "- beta"
      ]
    },
    {
      "metadata": {
        "id": "BP5oPuB9GPfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2176
        },
        "outputId": "d1188ea4-4d98-4870-ba4c-e42b4a3b0368"
      },
      "cell_type": "code",
      "source": [
        "#@title Run LDA\n",
        "\n",
        "topics = 10 #@param {type:\"integer\"}\n",
        "\n",
        "alpha = 0.1 #@param {type:\"number\"}\n",
        "\n",
        "beta = 0.01 #@param {type:\"number\"}\n",
        "\n",
        "no_top_words = 5\n",
        "\n",
        "no_top_documents = 3\n",
        "\n",
        "\n",
        "# Run LDA\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=topics, \n",
        "    doc_topic_prior=alpha, \n",
        "    topic_word_prior=beta, \n",
        "    max_iter=20, \n",
        "    learning_method='online', \n",
        "    learning_offset=50.,\n",
        "    random_state=0).fit(tf)\n",
        "lda_W = lda_model.transform(tf)\n",
        "lda_H = lda_model.components_\n",
        "\n",
        "print(\"LDA Topics\")\n",
        "display_topics(lda_H, lda_W, tf_feature_names, documents, no_top_words, no_top_documents)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA Topics\n",
            "------------------------------\n",
            " Topic  0  :\n",
            "[ the | to | Biggest | and | in ]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "( 27 ) ktgeiss@miavx1.acs.muohio.edu writes: > Lake State/Maine in finals...WHO WON?   Please post. Maine 5  ...\n",
            "\t [0.00588241 0.00588245 0.15394474 0.00588248 0.79899565 0.00588245\n",
            " 0.00588242 0.00588245 0.00588252 0.00588243]\n",
            "------------------------------\n",
            " Topic  1  :\n",
            "[ Rangers | Hartford | the | Amonte | Turcotte ]\n",
            "( 78 ) Hartford                         1 1 3--5 NY Rangers                       1 2 1--4 First period      ...\n",
            "\t [0.0009804  0.74982755 0.12890367 0.00098041 0.00098041 0.11440593\n",
            " 0.00098041 0.00098041 0.0009804  0.0009804 ]\n",
            "( 80 ) x - Clinched Division Title y - Clinched Playoff Berth Hartford Whalers   (24-49-5)   1   1   3   -   ...\n",
            "\t [0.0009091  0.60927162 0.00090944 0.00090911 0.00090911 0.38345518\n",
            " 0.00090911 0.00090911 0.00090911 0.00090911]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "------------------------------\n",
            " Topic  2  :\n",
            "[ the | to | and | of | in ]\n",
            "( 65 ) The FLYERS team that can beat any team on any night showed up at the Spectrum Sunday night, and domi  ...\n",
            "\t [5.04812643e-05 5.04816921e-05 9.99545650e-01 5.04815239e-05\n",
            " 5.04812880e-05 5.04981901e-05 5.04814232e-05 5.04815407e-05\n",
            " 5.04814403e-05 5.04813675e-05]\n",
            "( 74 ) In article <rauser.734062608@sfu.ca> rauser@fraser.sfu.ca (Richard John Rauser) writes: >   Ten year  ...\n",
            "\t [1.69495784e-04 1.69496300e-04 9.98474533e-01 1.69496482e-04\n",
            " 1.69495692e-04 1.69498592e-04 1.69495616e-04 1.69496673e-04\n",
            " 1.69495905e-04 1.69495676e-04]\n",
            "( 18 ) In <1993Apr5.182124.17415@ists.ists.ca> dchhabra@stpl.ists.ca (Deepak Chhabra) writes: >Dean J. Falc  ...\n",
            "\t [1.82157116e-04 1.82157828e-04 9.98360578e-01 1.82157514e-04\n",
            " 1.82157062e-04 1.82162864e-04 1.82157099e-04 1.82158181e-04\n",
            " 1.82157027e-04 1.82157607e-04]\n",
            "------------------------------\n",
            " Topic  3  :\n",
            "[ the | dg | Wayne | and | rtp ]\n",
            "( 73 ) Could anyone recommend a mail order distributor for hockey equipment.     Thanks in Advance     Wayn  ...\n",
            "\t [0.00357151 0.00357152 0.09634708 0.87508074 0.00357151 0.00357161\n",
            " 0.0035715  0.00357152 0.00357151 0.00357151]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "------------------------------\n",
            " Topic  4  :\n",
            "[ Maine | Lake | WHO | post | WON ]\n",
            "( 55 ) ktgeiss@miavx1.acs.muohi writes: >Lake State/Maine in finals...WHO WON?   Please post. Maine 5, LSSU  ...\n",
            "\t [0.00555563 0.00555566 0.06564518 0.0055557  0.8899094  0.00555569\n",
            " 0.00555562 0.00555568 0.0055558  0.00555565]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "( 27 ) ktgeiss@miavx1.acs.muohio.edu writes: > Lake State/Maine in finals...WHO WON?   Please post. Maine 5  ...\n",
            "\t [0.00588241 0.00588245 0.15394474 0.00588248 0.79899565 0.00588245\n",
            " 0.00588242 0.00588245 0.00588252 0.00588243]\n",
            "------------------------------\n",
            " Topic  5  :\n",
            "[ 55 | 11 | 10 | 18 | 68 ]\n",
            "( 81 ) Here are the standings after the April 6 update.  I'll be leaving for Japan in 1.5 hours, and I won'  ...\n",
            "\t [5.60554536e-05 5.60559741e-05 5.60622133e-05 5.60556211e-05\n",
            " 5.60555915e-05 9.99495493e-01 5.60555875e-05 5.60555943e-05\n",
            " 5.60555656e-05 5.60555166e-05]\n",
            "( 82 ) Here is the price list for the week April 6 to April 12.  - Andrew Buy Sell Pts Team Player 157.5 14  ...\n",
            "\t [8.05164723e-05 8.05166833e-05 8.05191974e-05 8.05164674e-05\n",
            " 8.05164648e-05 9.99275349e-01 8.05166319e-05 8.05164978e-05\n",
            " 8.05164540e-05 8.05164790e-05]\n",
            "( 70 ) Scoring stats for the Swedish NHL players, April 5:  Mats Sundin watch:    Most points during a seas  ...\n",
            "\t [1.76059053e-04 1.76062670e-04 1.76083232e-04 1.76059437e-04\n",
            " 1.76059880e-04 9.98415438e-01 1.76059675e-04 1.76059279e-04\n",
            " 1.76059247e-04 1.76059159e-04]\n",
            "------------------------------\n",
            " Topic  6  :\n",
            "[ 55 | the | and | to | of ]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "( 27 ) ktgeiss@miavx1.acs.muohio.edu writes: > Lake State/Maine in finals...WHO WON?   Please post. Maine 5  ...\n",
            "\t [0.00588241 0.00588245 0.15394474 0.00588248 0.79899565 0.00588245\n",
            " 0.00588242 0.00588245 0.00588252 0.00588243]\n",
            "------------------------------\n",
            " Topic  7  :\n",
            "[ the | to | of | and | that ]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "( 27 ) ktgeiss@miavx1.acs.muohio.edu writes: > Lake State/Maine in finals...WHO WON?   Please post. Maine 5  ...\n",
            "\t [0.00588241 0.00588245 0.15394474 0.00588248 0.79899565 0.00588245\n",
            " 0.00588242 0.00588245 0.00588252 0.00588243]\n",
            "------------------------------\n",
            " Topic  8  :\n",
            "[ the | LSSU | Maine | beat | to ]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "( 27 ) ktgeiss@miavx1.acs.muohio.edu writes: > Lake State/Maine in finals...WHO WON?   Please post. Maine 5  ...\n",
            "\t [0.00588241 0.00588245 0.15394474 0.00588248 0.79899565 0.00588245\n",
            " 0.00588242 0.00588245 0.00588252 0.00588243]\n",
            "------------------------------\n",
            " Topic  9  :\n",
            "[ the | and | in | of | on ]\n",
            "( 5 ) Maine beat LSSU 5-4.  ...\n",
            "\t [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "( 8 ) Lake State/Maine in finals...WHO WON?   Please post.  ...\n",
            "\t [0.01000009 0.01000019 0.08505583 0.01000025 0.83494263 0.01000036\n",
            " 0.01000009 0.01000021 0.01000019 0.01000015]\n",
            "( 27 ) ktgeiss@miavx1.acs.muohio.edu writes: > Lake State/Maine in finals...WHO WON?   Please post. Maine 5  ...\n",
            "\t [0.00588241 0.00588245 0.15394474 0.00588248 0.79899565 0.00588245\n",
            " 0.00588242 0.00588245 0.00588252 0.00588243]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "80GMbeBiV9T7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get Topic Distributions:\n"
      ]
    },
    {
      "metadata": {
        "id": "_BFnUvDbWBGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7adc6bc5-20a5-4cb2-c4dc-368e7ab74ffb"
      },
      "cell_type": "code",
      "source": [
        "#@title Topic Distributions\n",
        "\n",
        "\n",
        "print(\"Topic Distributions: \")\n",
        "\n",
        "bounds = (0,5)\n",
        "tds = lda_model.transform(tf[bounds[0]:bounds[1]])\n",
        "for x in range(bounds[0],bounds[1]):\n",
        "  print(\"Doc\",x,tds[x])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic Distributions: \n",
            "Doc 0 [3.42472944e-04 3.42474341e-04 9.96917737e-01 3.42474380e-04\n",
            " 3.42473456e-04 3.42473470e-04 3.42473104e-04 3.42474792e-04\n",
            " 3.42473294e-04 3.42473269e-04]\n",
            "Doc 1 [5.29122340e-04 5.29129635e-04 9.95237882e-01 5.29127051e-04\n",
            " 5.29122158e-04 5.29126909e-04 5.29121516e-04 5.29124067e-04\n",
            " 5.29121323e-04 5.29122886e-04]\n",
            "Doc 2 [0.00119051 0.00119051 0.98928541 0.00119051 0.00119051 0.0011905\n",
            " 0.00119051 0.00119051 0.00119051 0.00119051]\n",
            "Doc 3 [0.02500072 0.02500046 0.02500464 0.02500077 0.02501747 0.02500023\n",
            " 0.02500064 0.02500061 0.77497393 0.02500053]\n",
            "Doc 4 [3.50893495e-04 3.50894558e-04 9.96841946e-01 3.50894216e-04\n",
            " 3.50893683e-04 3.50899034e-04 3.50893747e-04 3.50893998e-04\n",
            " 3.50895423e-04 3.50896102e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vtzhJ6BZNQ2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get topics for a given  sample:"
      ]
    },
    {
      "metadata": {
        "id": "S4zVOinlMBRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "\n",
        "text = \"this is an example\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"Topic Distribution: \", lda_model.transform(tf_vectorizer.transform([text])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}