{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_TopicModels.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/librairy/notebooks/blob/master/Intro_TopicModels.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "AVx3oh5JCi_F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This Google Colab Notebook serves as an introduction to Probabilistic Topic Models. Textual data can be loaded from a Google Sheet and topics derived from  LDA can be generated. \n",
        "\n",
        "First, it is necessary to indicate the training google sheet and the number of words to show per topic.\n"
      ]
    },
    {
      "metadata": {
        "id": "UcubynMaDbzt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Google Colab Authentication\n",
        "!pip install --upgrade -q gspread\n",
        "#!pip install -q gensim\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
        "    for topic_idx, topic in enumerate(H):\n",
        "        print(\"-\"*30)\n",
        "        print(\" Topic \",(topic_idx),\" :\")\n",
        "        print(\"[\",\" | \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-no_top_words - 1:-1]]),\"]\")\n",
        "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
        "        for doc_index in top_doc_indices:\n",
        "            print(\"(\",doc_index,\")\",documents[doc_index], W[doc_index])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXu9rcR2Dmz7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Load and preview data from a Google Sheet\n",
        "\n",
        "googlesheet_filename = 'sample' #@param {type:\"string\"}\n",
        "data_rows_to_preview = 10 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open(googlesheet_filename).sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# convert the 2nd column values to a list\n",
        "documents = []\n",
        "for row in rows[1:]:\n",
        "  documents.append(row[1])\n",
        "  \n",
        "#print(documents)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "dataset_df = pd.DataFrame.from_records(rows)\n",
        "dataset_df.head(n=data_rows_to_preview)\n",
        "\n",
        "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
        "tf_vectorizer = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    min_df=2,\n",
        "    max_df=0.95,\n",
        "    lowercase=True,\n",
        "    ngram_range=(1,1)\n",
        ")\n",
        "tf = tf_vectorizer.fit_transform(documents)\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "vocab = tf_vectorizer.vocabulary_\n",
        "\n",
        "print(\"Vocabulary Size: \", len(tf_feature_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmTsfABkDzF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now it's time to build a topic model by setting values for:\n",
        "- number of topics\n",
        "- alpha\n",
        "- beta"
      ]
    },
    {
      "metadata": {
        "id": "BP5oPuB9GPfv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Run LDA\n",
        "\n",
        "topics = 4 #@param {type:\"integer\"}\n",
        "\n",
        "alpha = 0.1 #@param {type:\"number\"}\n",
        "\n",
        "beta = 0.1 #@param {type:\"number\"}\n",
        "\n",
        "no_top_words = 5\n",
        "\n",
        "no_top_documents = 3\n",
        "\n",
        "\n",
        "# Run LDA\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=topics, \n",
        "    doc_topic_prior=alpha, \n",
        "    topic_word_prior=beta, \n",
        "    max_iter=20, \n",
        "    learning_method='online', \n",
        "    learning_offset=50.,\n",
        "    random_state=0).fit(tf)\n",
        "lda_W = lda_model.transform(tf)\n",
        "lda_H = lda_model.components_\n",
        "\n",
        "print(\"LDA Topics\")\n",
        "display_topics(lda_H, lda_W, tf_feature_names, documents, no_top_words, no_top_documents)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "80GMbeBiV9T7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get Topic Distributions:\n"
      ]
    },
    {
      "metadata": {
        "id": "_BFnUvDbWBGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Topic Distributions\n",
        "\n",
        "\n",
        "print(\"Topic Distributions: \")\n",
        "\n",
        "bounds = (0,5)\n",
        "tds = lda_model.transform(tf[bounds[0]:bounds[1]])\n",
        "for x in range(bounds[0],bounds[1]):\n",
        "  print(\"Doc\",x,tds[x])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vtzhJ6BZNQ2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get topics for a given  sample:"
      ]
    },
    {
      "metadata": {
        "id": "S4zVOinlMBRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "\n",
        "text = \"this is an example\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"Topic Distribution: \", lda_model.transform(tf_vectorizer.transform([text])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}